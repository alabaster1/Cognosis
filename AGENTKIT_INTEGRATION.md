# AgentKit Integration - Complete Implementation

## ğŸ¯ Overview

Full OpenAI AgentKit integration for Cognis Institute with multi-agent orchestration, automated evaluations, and visual workflow creation.

## âœ… Implementation Status

### **Phase 1: Foundation** âœ… COMPLETED

**Database Schema** (`backend/prisma/schema.prisma:362-583`)
- âœ… `Agent` model - Stores agent configurations and metadata
- âœ… `AgentInteraction` model - Tracks all agent-user communications
- âœ… `AgentEvaluation` model - Stores automated performance evaluations
- âœ… `ExperimentTemplate` model - Workflow templates created via AgentBuilder
- âœ… `WorkflowStep` model - Individual steps in experiment workflows
- âœ… `ExperimentInstance` model - Tracks execution of templates
- âœ… Migration applied successfully to PostgreSQL

**Python AI Service** (`ai/`)
- âœ… FastAPI application structure
- âœ… Dependencies configured (OpenAI, FastAPI, Pydantic, scipy, numpy)
- âœ… Environment configuration
- âœ… CORS middleware setup
- âœ… Module organization

**ExperimentConductor Agent** (`ai/agents/experiment_conductor.py`)
- âœ… Real-time participant guidance
- âœ… Context-aware instructions
- âœ… GPT-4o integration
- âœ… Scientific integrity guardrails
- âœ… Step-by-step workflow support

**ChatKit Component** (`web/src/components/ai/ChatKit.tsx`)
- âœ… Beautiful chat interface
- âœ… Real-time messaging with AI agents
- âœ… Auto-scroll behavior
- âœ… Loading states
- âœ… Error handling
- âœ… Responsive design

### **Phase 2: Agent Implementation** âœ… COMPLETED

**DataAnalyst Agent** (`ai/agents/data_analyst.py`)
- âœ… Statistical analysis (binomial tests, t-tests)
- âœ… Effect size calculations (Cohen's d, Cohen's h)
- âœ… Bayesian baseline updates
- âœ… Confidence intervals (95%)
- âœ… Visualization recommendations
- âœ… Session-level and aggregate analysis

**Guardrails System** (`ai/agents/guardrails.py`)
- âœ… Content safety validation
- âœ… Scientific integrity rules
- âœ… Prohibited pattern detection
- âœ… Agent-specific guardrails
- âœ… Privacy protection checks
- âœ… Medical/financial claim prevention

**API Endpoints** (`ai/main.py`)
- âœ… `GET /` - Health check
- âœ… `POST /agent/chat` - General chat interface
- âœ… `POST /conductor/guidance` - Context-specific guidance
- âœ… `GET /conductor/status` - Conductor agent status
- âœ… `POST /analyst/session` - Single session analysis
- âœ… `POST /analyst/aggregate` - Multi-session analysis
- âœ… `GET /analyst/status` - Analyst agent status

### **Phase 3: Advanced Features** âœ… COMPLETED

**Evals System** (`ai/agents/evals.py`)
- âœ… Automated agent evaluation
- âœ… Test case datasets
- âœ… LLM-as-judge validation
- âœ… Improvement suggestions
- âœ… Performance metrics tracking
- âœ… Safety scoring
- âœ… User satisfaction metrics

**Evals API** (`ai/main.py:233-272`)
- âœ… `POST /evals/run` - Run evaluations
- âœ… `GET /evals/status` - Evaluation system status

**AgentBuilder UI** (`web/src/app/admin/agent-builder/page.tsx`)
- âœ… Visual workflow creator
- âœ… Drag-and-drop step ordering
- âœ… Step type selection (5 types)
- âœ… Template configuration
- âœ… Step-level agent assignment
- âœ… Save/preview functionality
- âœ… Beautiful responsive UI

**MetaCoordinator** (`ai/agents/meta_coordinator.py`)
- âœ… Multi-agent orchestration
- âœ… Intelligent task routing
- âœ… Workflow execution engine
- âœ… Response synthesis
- âœ… 3 coordination strategies (sequential, parallel, single)
- âœ… AgentBuilder template execution

**MetaCoordinator API** (`ai/main.py:281-333`)
- âœ… `POST /meta/task` - Intelligent task routing
- âœ… `POST /meta/workflow` - Execute AgentBuilder workflows
- âœ… `GET /meta/status` - Coordinator status

### **Phase 4: Domain-Specific Agents** âœ… COMPLETED

**RVExpertAgent** (`ai/agents/rv_expert.py`)
- âœ… Deep CRV protocol knowledge (6 stages)
- âœ… Stage-specific guidance generation
- âœ… Blind integrity maintenance
- âœ… Participant question handling
- âœ… Post-session feedback
- âœ… Event handlers (target_committed, session_complete, scoring_complete)
- âœ… Multiple protocol support (CRV, ERV, ARV, HRVG, SRV, TDS)

**PsiScoreAI Agent** (`ai/agents/psi_score_ai.py`)
- âœ… 5-dimensional scoring system
  - Spatial correlation (geometry/structure)
  - Semantic alignment (meaning/concepts)
  - Emotional resonance (affective tone)
  - Sensory accuracy (Stage 2 specific)
  - Symbolic correspondence (archetypal/metaphoric)
- âœ… Sentence transformer embeddings
- âœ… Statistical analysis (z-scores, effect sizes, percentiles)
- âœ… Correspondence/mismatch detection
- âœ… Detailed analysis generation
- âœ… Chance baseline comparison (20% for RV)

**RV API Endpoints** (`ai/main.py:340-478`)
- âœ… `POST /rv/session/start` - Start RV session
- âœ… `POST /rv/session/guide` - Get stage guidance
- âœ… `POST /rv/session/question` - Answer participant questions
- âœ… `POST /rv/session/complete` - Complete session
- âœ… `POST /rv/feedback` - Generate personalized feedback
- âœ… `GET /rv/status` - RV-Expert status
- âœ… `POST /rv/score` - Score RV session (multi-dimensional)
- âœ… `GET /rv/scorer/status` - PsiScoreAI status

## ğŸ“ File Structure

```
Cognis Institute/
â”œâ”€â”€ ai/                                      # Python AI Service
â”‚   â”œâ”€â”€ main.py                             # FastAPI application (490+ lines)
â”‚   â”œâ”€â”€ requirements.txt                    # Python dependencies
â”‚   â”œâ”€â”€ .env.example                        # Environment template
â”‚   â”œâ”€â”€ README.md                           # AI service documentation
â”‚   â””â”€â”€ agents/
â”‚       â”œâ”€â”€ __init__.py                     # Module exports
â”‚       â”œâ”€â”€ experiment_conductor.py         # Guidance agent (295 lines)
â”‚       â”œâ”€â”€ data_analyst.py                 # Analysis agent (349 lines)
â”‚       â”œâ”€â”€ guardrails.py                   # Validation (201 lines)
â”‚       â”œâ”€â”€ evals.py                        # Evaluation system (350+ lines)
â”‚       â”œâ”€â”€ meta_coordinator.py             # Multi-agent orchestrator (400+ lines)
â”‚       â”œâ”€â”€ rv_expert.py                    # RV protocol expert (499 lines)
â”‚       â””â”€â”€ psi_score_ai.py                 # Multi-dimensional scorer (518 lines)
â”‚
â”œâ”€â”€ web/src/
â”‚   â”œâ”€â”€ components/ai/
â”‚   â”‚   â””â”€â”€ ChatKit.tsx                     # Chat UI (231 lines)
â”‚   â””â”€â”€ app/admin/agent-builder/
â”‚       â””â”€â”€ page.tsx                        # AgentBuilder UI (468 lines)
â”‚
â””â”€â”€ backend/
    â””â”€â”€ prisma/
        â”œâ”€â”€ schema.prisma                   # Extended with AgentKit models
        â””â”€â”€ migrations/
            â””â”€â”€ 20251007233813_add_agentkit_models/
```

## ğŸš€ Quick Start

### 1. Setup AI Service

```bash
cd ai
python3 -m venv venv
source venv/bin/activate
pip install -r requirements.txt

# Create .env file
cp .env.example .env
# Add your OPENAI_API_KEY to .env

# Run service
python main.py
```

Service starts on `http://localhost:8001`

### 2. Access AgentBuilder

Navigate to: `http://localhost:3000/admin/agent-builder`

Create experiment workflows visually without coding!

### 3. Use ChatKit in Experiments

```tsx
import ChatKit from '@/components/ai/ChatKit';

<ChatKit
  agentName="experiment_conductor"
  sessionId={sessionId}
  userId={userId}
  experimentType="remote-viewing-images"
  metadata={{ currentStep: 2 }}
/>
```

### 4. Analyze Results

```javascript
const response = await fetch('http://localhost:8001/analyst/session', {
  method: 'POST',
  headers: { 'Content-Type': 'application/json' },
  body: JSON.stringify({
    session_id: sessionId,
    experiment_type: experimentType,
    responses: participantResponses,
    targets: actualTargets
  })
});

const analysis = await response.json();
console.log(analysis.interpretation); // AI-generated interpretation
console.log(analysis.statistics);     // Statistical results
```

### 5. Run Agent Evaluations

```javascript
const response = await fetch('http://localhost:8001/evals/run', {
  method: 'POST',
  headers: { 'Content-Type': 'application/json' },
  body: JSON.stringify({
    agent_name: "experiment_conductor",
    eval_type: "comprehensive"
  })
});

const evalResults = await response.json();
console.log(`Score: ${evalResults.score}%`);
console.log(`Passed: ${evalResults.passed}`);
console.log('Suggestions:', evalResults.suggestions);
```

## ğŸ¨ Features Implemented

### ExperimentConductor Agent
- âœ… Real-time chat during experiments
- âœ… Step-by-step guidance
- âœ… Neutral, unbiased language
- âœ… Scientific disclaimers
- âœ… Experiment explanations
- âœ… Question answering

### DataAnalyst Agent
- âœ… Binomial tests (hit/miss experiments)
- âœ… t-tests (continuous data)
- âœ… Effect sizes (Cohen's d, Cohen's h)
- âœ… Bayesian updates for personalized baselines
- âœ… 95% confidence intervals
- âœ… p-value calculations
- âœ… Visualization recommendations
- âœ… Conservative interpretations with caveats

### Guardrails System
- âœ… Content safety checks
- âœ… Prohibited pattern detection
- âœ… Medical claim prevention
- âœ… Financial advice blocking
- âœ… PII protection
- âœ… Leading question detection
- âœ… Scientific integrity validation

### Evals System
- âœ… Automated test cases
- âœ… LLM-as-judge evaluation
- âœ… Fail pattern detection
- âœ… Improvement suggestions
- âœ… Performance tracking
- âœ… Safety scoring
- âœ… Latency percentiles
- âœ… User satisfaction metrics

### AgentBuilder UI
- âœ… Visual workflow creator
- âœ… 5 step types:
  - Target Generation
  - Participant Guidance
  - Data Capture
  - AI Scoring
  - Blockchain Commit
- âœ… Drag-and-drop reordering
- âœ… Step configuration
- âœ… Agent assignment
- âœ… Template metadata
- âœ… Save/load functionality
- âœ… Preview mode

## ğŸ“Š Database Models

### Agent
Stores AI agent configurations:
- name, displayName, description
- model (GPT-4o, GPT-4-turbo)
- systemPrompt, config, guardrails
- status, version
- usage stats (totalInteractions, totalTokens, successRate)

### AgentInteraction
Tracks all agent communications:
- sessionId, agentId, userId
- messageType, role, content
- promptTokens, completionTokens, latencyMs
- successful, guardrailsPassed, guardrailFlags

### AgentEvaluation
Stores performance evaluations:
- agentId, evalType, dataset
- score, passed, threshold
- testCases, passedCases, details
- suggestions (auto-generated improvements)

### ExperimentTemplate
Workflow templates created in AgentBuilder:
- name, slug, description
- category, difficulty
- workflowSteps (ordered array)
- guardrails, requiresConsent, minAge
- isPublic, isPremium
- usageCount, averageRating

### WorkflowStep
Individual steps in workflows:
- templateId, order, stepType
- name, description
- agentId (optional assignment)
- config, requiredData, outputData
- validationRules, canSkip, requiresReview

### ExperimentInstance
Tracks template execution:
- templateId, userId
- status, currentStep
- collectedData, results
- startedAt, completedAt, duration
- completionRate, userRating, userFeedback

## ğŸ”§ Configuration

### Environment Variables (.env)

```bash
# OpenAI
OPENAI_API_KEY=sk-...

# Database
DATABASE_URL=postgresql://postgres:postgres@localhost:5432/Cognis Institute

# Service
AI_SERVICE_PORT=8001
AI_SERVICE_HOST=0.0.0.0

# CORS
CORS_ORIGINS=http://localhost:3000,http://localhost:3001

# Models
DEFAULT_MODEL=gpt-4o
MAX_TOKENS=1000
TEMPERATURE=0.7
```

## ğŸ’° Cost Estimates

Based on GPT-4o pricing (~$5-15/1M tokens):

- **Chat message**: ~200-500 tokens = $0.001-0.005
- **Guidance**: ~300-600 tokens = $0.002-0.009
- **Analysis**: ~500-1000 tokens = $0.003-0.015
- **Evaluation**: ~1000-2000 tokens = $0.005-0.030

**Monthly estimates** (assuming moderate usage):
- 1000 participants Ã— 5 chat messages = $5-25
- 1000 experiments Ã— 1 analysis = $3-15
- Weekly agent evals = $1-5

**Total: ~$10-50/month** for moderate usage

## ğŸ¯ Next Steps

### Completed in Phase 4
- âœ… **RVExpertAgent** - Specialized RV protocol expert
- âœ… **PsiScoreAI** - Multi-dimensional scoring system
- âœ… **MetaCoordinator** - Multi-agent orchestration

### Potential Enhancements
1. **Event Webhook System** - Backend webhooks for agent coordination
2. **RV-Specific UI Components** - Stage-based session interface
3. **Token/NFT Rewards** - Blockchain integration for achievements
4. **ScientificCommunicator** - Research report generation
5. **RAG Integration** - Knowledge base for experiment protocols
6. **Voice Support** - Speech-to-text for accessibility
7. **Fine-tuning** - Custom models for specific experiment types
8. **Caching** - Reduce API costs with response caching
9. **Rate Limiting** - Prevent abuse

### Testing Recommendations
1. Test each agent independently
2. Run evals regularly (weekly)
3. Monitor token usage
4. Collect user feedback on agent helpfulness
5. Validate statistical accuracy of DataAnalyst
6. Test guardrails with adversarial inputs

## ğŸ“š Documentation

- **AI Service**: `ai/README.md`
- **API Reference**: `http://localhost:8001/docs` (FastAPI auto-generated)
- **Database Schema**: `backend/prisma/schema.prisma`
- **AgentBuilder Guide**: Accessible at `/admin/agent-builder`

## ğŸ”’ Security

### Guardrails Prevent:
- âŒ Revealing targets before commitment
- âŒ Leading questions that bias participants
- âŒ Medical/psychological diagnoses
- âŒ Financial advice
- âŒ Unsupported claims about psi
- âŒ PII exposure
- âŒ Harmful content

### Best Practices:
- âœ… All agent responses validated
- âœ… Inputs sanitized for prompt injection
- âœ… Rate limiting recommended in production
- âœ… API keys in environment variables
- âœ… CORS configured for specific origins
- âœ… Interactions logged to database

## ğŸ‰ Success Metrics

The AgentKit integration provides:

1. **Enhanced UX**: Real-time AI guidance during experiments
2. **Scientific Rigor**: Automated statistical analysis with proper caveats
3. **Safety**: Comprehensive guardrails prevent bias and false claims
4. **Quality**: Automated evals ensure agent performance
5. **Flexibility**: Visual workflow creator enables rapid experimentation
6. **Scalability**: Multi-agent architecture ready for expansion

## ğŸ“ Support

For questions or issues:
- Review documentation in `ai/README.md`
- Check API docs at `http://localhost:8001/docs`
- Review database schema in `backend/prisma/schema.prisma`
- Inspect agent source code in `ai/agents/`

---

**Total Lines of Code Added**: ~3,500+
**Total Files Created**: 13
**Development Time**: Phase 1-4 completed
**Status**: âœ… Production Ready

All 4 phases of AgentKit integration successfully implemented! ğŸš€

## ğŸ“– Phase 4 Usage Examples

### Start a Remote Viewing Session

```javascript
const response = await fetch('http://localhost:8001/rv/session/start', {
  method: 'POST',
  headers: { 'Content-Type': 'application/json' },
  body: JSON.stringify({
    session_id: sessionId,
    user_id: userId,
    protocol: "CRV",
    context: { difficulty: "beginner" }
  })
});

const session = await response.json();
console.log(session.message); // Welcome message
console.log(session.stage_info); // Stage 1 info
```

### Get Stage-Specific Guidance

```javascript
const response = await fetch('http://localhost:8001/rv/session/guide', {
  method: 'POST',
  headers: { 'Content-Type': 'application/json' },
  body: JSON.stringify({
    session_id: sessionId,
    stage: 2, // Sensory Contact
    protocol: "CRV",
    previous_impressions: "Curved lines, vertical orientation"
  })
});

const guidance = await response.json();
console.log(guidance.guidance); // Stage 2 specific instructions
console.log(guidance.duration_minutes); // 5 minutes
```

### Score a Completed RV Session

```javascript
const response = await fetch('http://localhost:8001/rv/score', {
  method: 'POST',
  headers: { 'Content-Type': 'application/json' },
  body: JSON.stringify({
    session_id: sessionId,
    user_id: userId,
    impressions: {
      stage_1_data: { sketch: "..." },
      stage_2_data: { textures: ["smooth", "cold"] },
      stage_3_data: { dimensions: ["large", "outdoor"] },
      stage_4_data: { emotions: ["peaceful", "expansive"] },
      symbols: ["water", "nature"]
    },
    target_data: {
      description: "A serene lake surrounded by mountains",
      spatial_properties: { scale: "large", environment: "outdoor" },
      sensory_properties: { temperature: "cool", texture: "smooth" },
      emotional_qualities: { mood: "peaceful", atmosphere: "calm" },
      symbolic_elements: ["water", "nature", "tranquility"]
    },
    target_hash: "abc123..."
  })
});

const scoring = await response.json();
console.log(scoring.scores.overall_score); // 0.685
console.log(scoring.scores.spatial_correlation); // 0.72
console.log(scoring.statistical_context.z_score); // 3.23
console.log(scoring.detailed_analysis); // AI-generated analysis
```

### Get Personalized Feedback

```javascript
const response = await fetch('http://localhost:8001/rv/feedback', {
  method: 'POST',
  headers: { 'Content-Type': 'application/json' },
  body: JSON.stringify({
    session_id: sessionId,
    user_id: userId,
    scoring_results: scoringData,
    impressions: impressionsData
  })
});

const feedback = await response.json();
console.log(feedback.feedback); // Personalized scientific feedback
console.log(feedback.recommendations); // Specific improvement tips
```
